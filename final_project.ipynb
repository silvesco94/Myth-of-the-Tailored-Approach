{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silvesco94/zone_article1/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUNuAgiVF-tR"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The goal of this project is to address a critical question in baseball analytics: Which types of players are underpaid, overpaid, or fairly paid based on their on-field performance and contract details? By combining advanced machine learning techniques with detailed performance and contract data, the project aims to provide actionable insights into salary fairness across different player categories.\n",
        "\n",
        "**Which machine learning methods did you implement?**  \n",
        "The project implemented Ridge Regression, K-Means Clustering, Regression Models, Support Vector Machines (SVM), Ensemble Models (Random Forest and Gradient Boosting), and Neural Networks. Each method contributed uniquely to the analysis, providing a comprehensive and multi-faceted perspective on salary fairness.\n",
        "\n",
        "**Discuss the key contribution of each method to your analysis. If a method didn't contribute, discuss why it didn't. A sentence or two for each method is plenty.**  \n",
        "- *Ridge Regression*: This method was used for feature selection, helping to reduce multicollinearity and refine the dataset for subsequent analysis. It ensured the model considered the most impactful features while avoiding overfitting.  \n",
        "- *K-Means Clustering*: It grouped players into distinct categories based on performance metrics, providing a foundation to evaluate salary fairness within specific player types (e.g., Power Hitters, Balanced Hitters, Utility Players).  \n",
        "- *Regression Models*: These predicted fair salaries for players and categorized them as underpaid, overpaid, or fairly paid. This provided an objective baseline for salary fairness.  \n",
        "- *Support Vector Machines (SVM)*: SVMs analyzed the relationship between player categories (clusters) and salary fairness. They helped identify which clusters were more likely to contain underpaid or overpaid players.  \n",
        "- *Ensemble Models*: Random Forest and Gradient Boosting models captured complex interactions between features and provided more robust predictions of salary fairness. These models highlighted subtle patterns missed by simpler methods.  \n",
        "- *Neural Networks*: The neural network refined predictions further, capturing deeper nonlinear relationships between features and salary fairness. It improved classification accuracy and added robustness to the analysis.\n",
        "\n",
        "**Did all methods support your conclusions or did some provide conflicting results? If so they provided conflicting results, how did you reconcile the differences?**  \n",
        "While most methods aligned in identifying key trends, there were some discrepancies. For instance, SVM struggled with predicting overpaid players, as reflected in low precision and recall for that category. This was reconciled by prioritizing ensemble methods and neural networks for final predictions, as they provided better overall accuracy and insight into the patterns of salary fairness across player clusters.\n",
        "\n",
        "\n",
        "## Data Sources\n",
        "\n",
        "1. **Statcast Data**: Advanced player metrics, including launch angle, hard-hit percentage, and swing speed from Baseball Savant.\n",
        "2. **Player Contracts Data**: Salary and contract details, including annual average values (AAV) and total contract values from Spotrac.\n",
        "3. **Career Batting Stats**: Comprehensive batting data sourced from Fangraphs.\n",
        "\n",
        "This workflow integrates clustering to understand player types, regression to define salary fairness benchmarks, and classification to validate the alignment between these insights. By combining these methods with advanced ensemble models and neural networks, the project ensures robust, interpretable insights into salary fairness for teams and players.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnh2r88gGc9N"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kskIOsREZSR8",
        "outputId": "49a83580-1bf5-49d3-8651-0df8849581fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "jIj6XqAu5Kzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUHM7fMp-IWw"
      },
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Preprocessing and feature engineering\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Model training and evaluation\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.linear_model import RidgeCV, LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    mean_absolute_percentage_error, explained_variance_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "# Dimensionality reduction\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Optimization\n",
        "import optuna\n",
        "\n",
        "# Statistical analysis\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)"
      ],
      "metadata": {
        "id": "ToFKUZKY2O1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E69e5sr9GgnC"
      },
      "source": [
        "# Step 1 Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnflr_I2GkuL"
      },
      "source": [
        "## Merging data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "oEW7p39kGw0d",
        "outputId": "ce4d4996-e656-4f09-e3a0-066b2b531293"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/career batting.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0310982cfc6b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcareer_batting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/career batting.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcontracts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/contracts.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhitting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/hitting.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/career batting.csv'"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "career_batting = pd.read_csv('/content/career batting.csv')\n",
        "contracts = pd.read_csv('/content/contracts.csv')\n",
        "hitting = pd.read_csv('/content/hitting.csv')\n",
        "\n",
        "# Step 1: Standardize and Align the 'Player' Column\n",
        "# Fix Career Batting dataset\n",
        "career_batting.rename(columns={'Name': 'Player'}, inplace=True)\n",
        "\n",
        "# Fix Hitting dataset: Split 'last_name, first_name' into 'Player'\n",
        "hitting['Player'] = hitting['last_name, first_name'].str.split(', ').str[::-1].str.join(' ')\n",
        "hitting['Player'] = hitting['Player'].str.strip().str.title()\n",
        "\n",
        "# Standardize 'Player' column in all datasets\n",
        "contracts['Player'] = contracts['Player'].str.strip().str.title()\n",
        "career_batting['Player'] = career_batting['Player'].str.strip().str.title()\n",
        "\n",
        "# Step 2: Merge Datasets\n",
        "data = pd.merge(hitting, contracts, on='Player', how='inner')\n",
        "data = pd.merge(data, career_batting, on='Player', how='inner')\n",
        "\n",
        "# Step 3: Display Merge Results\n",
        "print(f\"Merged dataset contains {data.shape[0]} rows and {data.shape[1]} columns.\")\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FV8QOPJCIEsF"
      },
      "outputs": [],
      "source": [
        "# Rename columns for clarity and usability\n",
        "data.rename(columns={\n",
        "    'Team\\n                        Currently With': 'Current Team',\n",
        "    'Age\\n                        At Signing': 'Age at Signing'\n",
        "}, inplace=True)\n",
        "\n",
        "# Display the updated column names to confirm changes\n",
        "print(data.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRbw8DJGLL6n"
      },
      "source": [
        "Too keep this based on past performances I am elimnating any expected predicted stats such as xwoba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB1fzDUQLjuc"
      },
      "outputs": [],
      "source": [
        "# Remove columns starting with 'x' (e.g., xWOBA, xwOBA, etc.)\n",
        "columns_to_drop = [col for col in data.columns if col.lower().startswith('x')]\n",
        "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Display updated dataset columns to confirm\n",
        "print(f\"Remaining columns in the dataset: {data.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vmNBkM77omC"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln2Bdp-07sft"
      },
      "source": [
        "### Average Annual Value Distribution (Target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAuwyZHP8Bcw"
      },
      "outputs": [],
      "source": [
        "# Convert AAV to numeric by removing dollar signs and commas\n",
        "data['AAV'] = data['AAV'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
        "\n",
        "# Plot the distribution of AAV\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(data['AAV'], bins=30, edgecolor='k', alpha=0.7)\n",
        "plt.title('Distribution of Average Annual Value (AAV)', fontsize=14)\n",
        "plt.xlabel('AAV ($)', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGU5OW5-olL"
      },
      "source": [
        "\n",
        "This histogram shows the distribution of Average Annual Value (AAV) for player contracts, revealing a highly skewed distribution where most players earn significantly less, with a few earning substantially higher salaries. This imbalance will impact the regression and clustering models, as special care will be needed to handle the skewness (e.g., log transformation or robust scaling) to ensure fairness and accuracy when identifying overpaid and underpaid players."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXvMU2Rc_F_b"
      },
      "source": [
        "### Relationships between performance metrics and salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3sXfxEB_L4e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=data['woba'], y=data['AAV'])\n",
        "plt.title('Scatter Plot of AAV vs wOBA', fontsize=14)\n",
        "plt.xlabel('wOBA', fontsize=12)\n",
        "plt.ylabel('AAV ($)', fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmlTAT43_6rc"
      },
      "source": [
        "The scatter plot shows that higher woba values generally correspond to higher salaries, but there is significant variance, particularly at mid-range woba values, suggesting inconsistencies in how performance translates to pay. This variability indicates the need for models that capture nonlinear relationships and account for potential outliers when predicting salary fairness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5ynPEwkADgc"
      },
      "source": [
        "### Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14cKP2hb__xK"
      },
      "outputs": [],
      "source": [
        "# Filter numeric columns for correlation calculation, excluding irrelevant features\n",
        "numeric_data = data.select_dtypes(include=['float64', 'int64']).drop(columns=['player_id'], errors='ignore')\n",
        "\n",
        "# Identify the top 10 features most correlated with AAV\n",
        "correlation_with_aav = numeric_data.corr()['AAV'].abs().sort_values(ascending=False)\n",
        "top_10_features = correlation_with_aav.index[1:11]  # Exclude 'AAV' itself\n",
        "\n",
        "# Generate a heatmap for the top 10 features\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(numeric_data[top_10_features].corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlation Matrix of Top 10 Features Most Correlated with AAV (Excluding Less Relevent Columns)', fontsize=14)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKKyn9N3BROG"
      },
      "source": [
        "The heatmap indicates that features such as barrel, home_run, HR, and wOBA exhibit strong positive correlations with each other and with AAV, making them significant predictors of player salary. However, the high collinearity among these metrics underscores the need for feature selection techniques (e.g., Ridge regression) to prioritize the most impactful predictors while minimizing redundancy and improving model interpretability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXTmPjARDBYq"
      },
      "source": [
        "### Pairwise Scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7ECGNJEBYZK"
      },
      "outputs": [],
      "source": [
        "# Select the top features from the correlation heatmap for pairplot\n",
        "top_features_correlation = ['barrel', 'home_run', 'HR', 'Off', 'RBI', 'R', 'WAR', 'PA', 'out_zone_swing', 'woba']\n",
        "\n",
        "# Generate pairplot for the selected features\n",
        "sns.pairplot(data[top_features_correlation], diag_kind='kde', plot_kws={'alpha': 0.7})\n",
        "plt.suptitle('Pairwise Scatter Plots of Features from Correlation Heatmap', y=1.02, fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIf5_0OJDNIM"
      },
      "source": [
        "The pairwise scatter plots show strong linear and nonlinear relationships between many of the selected features (e.g., barrel, home_run, woba, and WAR). This indicates that these features are interrelated, which could introduce multicollinearity in regression models and clustering analysis. For clustering, the clear patterns suggest well-defined player groupings are possible; however, regularization techniques like Ridge regression can help address multicollinearity by prioritizing the most relevant features, ensuring both interpretability and robust model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbnZ5zDoEJMJ"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvpHGG2LFiUn"
      },
      "source": [
        "## Penalized Regression with Ridge\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiBjQZeaFl_F"
      },
      "outputs": [],
      "source": [
        "# Step 1: Drop irrelevant columns that won't affect clustering\n",
        "columns_to_drop = ['Current Team', 'Value', 'Pos', 'player_id', 'Player']\n",
        "numeric_data = data.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Step 2: Retain only numeric columns\n",
        "numeric_data = numeric_data.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Step 3: Define X (features) and y (target - AAV for salary prediction)\n",
        "X = numeric_data.drop(columns=['AAV'], errors='ignore')  # Drop 'AAV' from features\n",
        "y = data['AAV']  # Target variable is the player's salary (AAV)\n",
        "\n",
        "# Step 4: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Apply Ridge Regression with cross-validation to select the optimal alpha\n",
        "ridge = RidgeCV(alphas=np.logspace(-4, 4, 100), cv=5).fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Output model performance\n",
        "print(f\"Optimal Alpha: {ridge.alpha_}\")\n",
        "print(f\"Training Score: {ridge.score(X_train, y_train)}\")\n",
        "print(f\"Testing Score: {ridge.score(X_test, y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDWJID3BI8V3"
      },
      "source": [
        "\n",
        "The Ridge regression model achieved an optimal alpha of ~3944, with a training score of 0.49 and a testing score of 0.48, indicating moderate predictive power and a minimal gap between the two scores. While the scores suggest that the model captures some variance in player salary (AAV), other external factors not included in the dataset (e.g., market trends, team-specific strategies) likely play a role in salary determination. However, since the primary objective of the project is to provide interpretable clustering and salary fairness insights rather than perfect salary prediction, these scores are sufficient to proceed with meaningful analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-T7WJy8OMKX"
      },
      "source": [
        "## Clustering with Kmeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aTMkXlAPG4V"
      },
      "source": [
        "**Step 1: Standardize the Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0qnPx8ZONx3"
      },
      "outputs": [],
      "source": [
        "# Step 1: Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Features have been standardized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf0eeSY3PL8n"
      },
      "source": [
        "**Step 2: Determine the Optimal Number of Clusters Using the Elbow Method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFpkGtbFPPSP"
      },
      "outputs": [],
      "source": [
        "# Step 2: Determine the optimal number of clusters using the Elbow Method\n",
        "wcss = []  # Within-cluster sum of squares\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
        "    kmeans.fit(X_scaled)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the Elbow Method\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, 11), wcss, marker='o')\n",
        "plt.title('Elbow Method for Optimal Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1xWz1HsPpRW"
      },
      "source": [
        "The Elbow Method plot shows a noticeable \"elbow\" at 3 clusters, where the within-cluster sum of squares (WCSS) begins to decrease at a slower rate. This suggests that using 3 clusters would balance simplicity and the ability to capture meaningful groupings in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrDyruvvPr57"
      },
      "source": [
        "**Step 4: Apply K-Means Clustering with 3 Clusters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIOH1T0qPwi3"
      },
      "outputs": [],
      "source": [
        "optimal_clusters = 3\n",
        "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
        "cluster_labels = kmeans.fit_predict(X_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bbh2euaQPN1"
      },
      "source": [
        "**Visualize Clusters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Mrl0GgtRcAs"
      },
      "outputs": [],
      "source": [
        "# Calculate cluster centers\n",
        "cluster_centers = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)\n",
        "\n",
        "# Calculate the range of each feature across clusters\n",
        "feature_ranges = cluster_centers.max() - cluster_centers.min()\n",
        "\n",
        "# Rank features by their range across clusters\n",
        "cluster_feature_importance = feature_ranges.sort_values(ascending=False)\n",
        "print(\"Feature Importance for Clusters (based on range):\")\n",
        "print(cluster_feature_importance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7N1kBGNRt0m"
      },
      "source": [
        "The feature importance rankings based on the range across cluster centers indicate that RBI, home_run, and HR are the most defining features for distinguishing the clusters, suggesting that offensive performance metrics play a significant role in cluster differentiation. Similarly, features like barrel, PA, and out_zone_swing also contribute strongly, emphasizing both power-hitting tendencies and plate discipline as key traits in cluster separation. On the other hand, features with lower importance, such as BsR (base running), oz_swing_percent, and year, have minimal impact, indicating that these characteristics are less relevant in defining the player groupings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIM-xVtLQRem"
      },
      "outputs": [],
      "source": [
        "# Select top 10 features by importance\n",
        "top_features = cluster_feature_importance.head(10).index.tolist()\n",
        "\n",
        "# Examine cluster centers for top features\n",
        "top_cluster_centers = cluster_centers[top_features]\n",
        "print(\"Cluster Centers for Top Features:\")\n",
        "print(top_cluster_centers)\n",
        "\n",
        "# Visualize cluster centers to identify patterns\n",
        "plt.figure(figsize=(10, 6))\n",
        "top_cluster_centers.T.plot(kind='bar', figsize=(14, 8), colormap='viridis')\n",
        "plt.title(\"Top Feature Averages Across Clusters\", fontsize=16)\n",
        "plt.xlabel(\"Features\", fontsize=14)\n",
        "plt.ylabel(\"Cluster Center Values\", fontsize=14)\n",
        "plt.legend(title=\"Cluster\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvwflCFs9cq-"
      },
      "source": [
        "The cluster centers reveal distinct differences across the top features, which help characterize the player types within each cluster. Cluster 0 shows significantly high values in power-related metrics like RBI, home runs, HR, and SLG, indicating it likely represents \"Power Hitters.\" Cluster 1 has moderate values across most features, suggesting it includes \"Balanced Hitters\" with a focus on consistency rather than extremes. Cluster 2 exhibits the lowest values across all key metrics, particularly RBI and SLG, which aligns with the profile of \"Utility Players\" or players with lower offensive contributions.\n",
        "\n",
        "To label the clusters:\n",
        "- Cluster 0 can be labeled as \"Power Hitters\" based on their dominance in power metrics like RBI and SLG.\n",
        "- Cluster 1 can be labeled as \"Balanced Hitters\" given their moderate performance across metrics.\n",
        "- Cluster 2 can be labeled as \"Utility Players,\" as their overall contribution appears lower across the measured metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm-hThbz-cr1"
      },
      "outputs": [],
      "source": [
        "# Add the numeric cluster labels from KMeans to the dataset\n",
        "data['Cluster'] = cluster_labels  # This adds the numeric cluster labels (0, 1, 2) to the 'Cluster' column in the DataFrame\n",
        "\n",
        "# Define a dictionary for cluster labels\n",
        "cluster_labels_map = {\n",
        "    0: \"Power Hitters\",      # Cluster 0 corresponds to Power Hitters\n",
        "    1: \"Balanced Hitters\",   # Cluster 1 corresponds to Balanced Hitters\n",
        "    2: \"Utility Players\"     # Cluster 2 corresponds to Utility Players\n",
        "}\n",
        "\n",
        "# Map the descriptive cluster labels to the numeric clusters\n",
        "data['Cluster_Label'] = data['Cluster'].map(cluster_labels_map)\n",
        "\n",
        "# Check if the mapping is successful by displaying a sample of the dataset\n",
        "print(data[['Cluster', 'Cluster_Label']].drop_duplicates())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0fUas5UAtBH"
      },
      "source": [
        "## Regression Model to Define Salary Fairness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XbIEDhkBZhP"
      },
      "source": [
        "**Based on Ridge Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrtcqKvCA4Ws"
      },
      "outputs": [],
      "source": [
        "# Step 1: Predict salaries using the trained Ridge model\n",
        "y_test_pred = ridge.predict(X_test)\n",
        "\n",
        "# Step 2: Define a threshold for fairness (10% of average salary as an example)\n",
        "threshold = 0.1 * y.mean()\n",
        "\n",
        "# Step 3: Define salary fairness categories\n",
        "def classify_salary(actual, predicted, threshold):\n",
        "    if actual < predicted - threshold:\n",
        "        return \"Underpaid\"\n",
        "    elif actual > predicted + threshold:\n",
        "        return \"Overpaid\"\n",
        "    else:\n",
        "        return \"Fairly Paid\"\n",
        "\n",
        "# Step 4: Apply the classification logic to the test set\n",
        "fairness_labels = [\n",
        "    classify_salary(actual, predicted, threshold)\n",
        "    for actual, predicted in zip(y_test, y_test_pred)\n",
        "]\n",
        "\n",
        "# Step 5: Combine the results into a new DataFrame\n",
        "fairness_results = X_test.copy()\n",
        "fairness_results['Actual Salary'] = y_test\n",
        "fairness_results['Predicted Salary'] = y_test_pred\n",
        "fairness_results['Fairness'] = fairness_labels\n",
        "\n",
        "# Display a summary of the fairness classification\n",
        "print(fairness_results[['Actual Salary', 'Predicted Salary', 'Fairness']].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T2M1lT5DAHF"
      },
      "source": [
        "The salary fairness analysis evaluates whether a player's actual salary aligns with their predicted salary based on performance metrics. Using Ridge regression, salaries are predicted from player performance data, and fairness is determined by comparing actual and predicted salaries within a defined threshold. Players are categorized as \"Underpaid\" if their actual salary falls significantly below their performance-based prediction, \"Overpaid\" if their salary exceeds the prediction by a large margin, or \"Fairly Paid\" if the two are closely aligned, ensuring a performance-driven evaluation of compensation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2TAMT84Bgh0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot the fairness distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=fairness_results, x='Fairness', order=[\"Underpaid\", \"Fairly Paid\", \"Overpaid\"])\n",
        "plt.title(\"Salary Fairness Distribution\", fontsize=16)\n",
        "plt.xlabel(\"Fairness Category\", fontsize=14)\n",
        "plt.ylabel(\"Count\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIyIk0omDOHC"
      },
      "source": [
        "The distribution of salary fairness categories shows that the majority of players are classified as either \"Underpaid\" or \"Overpaid,\" with relatively fewer players falling into the \"Fairly Paid\" category. This suggests a potential mismatch between player performance and compensation for many players, emphasizing the need for performance-driven salary evaluations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmxKU5ibDaJI"
      },
      "source": [
        "**Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJaHKDQfDPTF"
      },
      "outputs": [],
      "source": [
        "# Evaluate Ridge regression performance\n",
        "mse = mean_squared_error(y_test, y_test_pred)\n",
        "mae = mean_absolute_error(y_test, y_test_pred)\n",
        "r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Model Performance Metrics:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"R-squared (R2): {r2:.2f}\")\n",
        "\n",
        "# Evaluate classification distribution\n",
        "fairness_distribution = fairness_results['Fairness'].value_counts(normalize=True) * 100\n",
        "print(\"\\nFairness Classification Distribution:\")\n",
        "print(fairness_distribution)\n",
        "\n",
        "# Visualize residuals\n",
        "residuals = y_test - y_test_pred\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(y_test, residuals, alpha=0.7)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title(\"Residuals of Actual vs. Predicted Salary\")\n",
        "plt.xlabel(\"Actual Salary\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq7vpdl_EFR7"
      },
      "source": [
        "Let's try some feature selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4ZVrBisEQsY"
      },
      "outputs": [],
      "source": [
        "# Use RFE with Linear Regression\n",
        "selector = RFE(estimator=LinearRegression(), n_features_to_select=10)  # Adjust the number of features\n",
        "selector = selector.fit(X_train, y_train)\n",
        "\n",
        "# Get selected features\n",
        "selected_features = X.columns[selector.support_]\n",
        "print(\"Selected Features by RFE:\")\n",
        "print(selected_features)\n",
        "\n",
        "# Train the model using only selected features\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "linear_model_rfe = LinearRegression()\n",
        "linear_model_rfe.fit(X_train_selected, y_train)\n",
        "y_test_pred_rfe = linear_model_rfe.predict(X_test_selected)\n",
        "\n",
        "# Evaluate the RFE model\n",
        "mse_rfe = mean_squared_error(y_test, y_test_pred_rfe)\n",
        "mae_rfe = mean_absolute_error(y_test, y_test_pred_rfe)\n",
        "r2_rfe = r2_score(y_test, y_test_pred_rfe)\n",
        "\n",
        "print(\"RFE Model Performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_rfe:.2f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_rfe:.2f}\")\n",
        "print(f\"R-squared (R2): {r2_rfe:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITlUqvqBEQaH"
      },
      "source": [
        "The results of the Recursive Feature Elimination (RFE) model reveal the following:\n",
        "\n",
        "The selected features (`woba`, `BB%`, `K%`, `ISO`, `BABIP`, `AVG`, `OBP`, `SLG`, `wOBA`, `WAR`) reflect a well-rounded set of performance metrics, including batting efficiency (`woba`, `OBP`), power (`ISO`, `SLG`), and overall player contribution (`WAR`). These features provide a balanced foundation for predicting salaries based on key aspects of player performance.\n",
        "\n",
        "Model performance metrics indicate moderate predictive accuracy. The Mean Squared Error (MSE) of \\( 6.06 \\times 10^{13} \\) and Mean Absolute Error (MAE) of \\( 5,034,050.13 \\) suggest that salary predictions deviate significantly from actual values on average. Additionally, the R-squared (R²) value of \\( 0.40 \\) highlights that the model explains only 40% of the variance in salary, leaving substantial room for improvement.\n",
        "\n",
        "The moderate R² score shows that while the selected features provide some explanatory power, the model does not fully capture the underlying patterns in the data. The relatively high MSE and MAE suggest that while the model has improved with a refined feature set, it still has limitations in accurately predicting player salaries. To improve, additional feature engineering, alternative modeling techniques (e.g., ensemble methods like Random Forest or Gradient Boosting), and careful reassessment of the dataset for outliers or salary discrepancies should be considered.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBT1XZseE9to"
      },
      "source": [
        "**Polynomial Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09xnELC7FCqB"
      },
      "outputs": [],
      "source": [
        "# Generate polynomial features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Train a linear model on polynomial features\n",
        "poly_model = LinearRegression()\n",
        "poly_model.fit(X_train_poly, y_train)\n",
        "y_test_pred_poly = poly_model.predict(X_test_poly)\n",
        "\n",
        "# Evaluate the polynomial model\n",
        "mse_poly = mean_squared_error(y_test, y_test_pred_poly)\n",
        "mae_poly = mean_absolute_error(y_test, y_test_pred_poly)\n",
        "r2_poly = r2_score(y_test, y_test_pred_poly)\n",
        "\n",
        "print(\"Polynomial Regression Model Performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_poly:.2f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_poly:.2f}\")\n",
        "print(f\"R-squared (R2): {r2_poly:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqS4IRLkFrGO"
      },
      "source": [
        "The Polynomial Regression model demonstrates poor performance, as reflected in its evaluation metrics. The Mean Squared Error (MSE) of \\( 3.67 \\times 10^{14} \\) and the Mean Absolute Error (MAE) of \\( 14,483,942.33 \\) indicate that the predictions are significantly off from actual values, with large errors on average.\n",
        "\n",
        "The R-squared (R²) value of \\( -2.65 \\) is particularly concerning, as it implies that the model performs worse than a simple baseline model (e.g., predicting the mean salary). This suggests that the polynomial regression model is likely overfitting the training data or failing to capture meaningful relationships in the features.\n",
        "\n",
        "The model's performance highlights the limitations of using polynomial regression in this context, especially when the dataset's relationships are not inherently nonlinear or when the feature set lacks sufficient predictive power. Simpler models like linear regression with regularization (e.g., Ridge) or ensemble models might perform better with these data characteristics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vPCzbnfFx6t"
      },
      "source": [
        "## Ensemble Methods for Determining Pay Equity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otMrwtcYGOIH"
      },
      "outputs": [],
      "source": [
        "# Step 1: Apply Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate Random Forest Model\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"Random Forest Model Performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_rf:.2f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_rf:.2f}\")\n",
        "print(f\"R-squared (R2): {r2_rf:.2f}\")\n",
        "\n",
        "# Step 2: Apply Gradient Boosting Regressor\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate Gradient Boosting Model\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "\n",
        "print(\"\\nGradient Boosting Model Performance:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_gb:.2f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_gb:.2f}\")\n",
        "print(f\"R-squared (R2): {r2_gb:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcAELG5AHj-S"
      },
      "source": [
        "This still isn't giving me a strong predictor. Let me do some feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5hz7eqJHyiz"
      },
      "source": [
        "**Check Correlation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F33AensYHtgY"
      },
      "outputs": [],
      "source": [
        "# Ensure only numeric columns are used for correlation\n",
        "numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Check correlations with AAV\n",
        "if 'AAV' in numeric_data.columns:\n",
        "    correlation_with_aav = numeric_data.corr()['AAV'].sort_values(ascending=False)\n",
        "    print(\"Correlation of features with AAV:\")\n",
        "    print(correlation_with_aav.head(20))  # Display top 20 correlations\n",
        "else:\n",
        "    print(\"Error: 'AAV' column not found in the numeric data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QpzzESIeD9"
      },
      "source": [
        "**Run the models with interactions and removing low correlations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4-mBzn4Icr8"
      },
      "outputs": [],
      "source": [
        "# Step 2: Remove features with low correlation (e.g., less than 0.3)\n",
        "low_corr_threshold = 0.3  # Adjust threshold as needed\n",
        "low_corr_features = correlation_with_aav[correlation_with_aav.abs() < low_corr_threshold].index.tolist()\n",
        "data = data.drop(columns=low_corr_features, errors='ignore')\n",
        "print(f\"Removed low correlation features: {low_corr_features}\")\n",
        "\n",
        "# Step 3: Add interaction terms for high-correlation features\n",
        "data['home_run_RBI'] = data['home_run'] * data['RBI']  # Interaction of power metrics\n",
        "data['barrel_WAR'] = data['barrel'] * data['WAR']      # Interaction of power and value metrics\n",
        "data['PA_R'] = data['PA'] * data['R']                 # Interaction of plate appearances and runs\n",
        "\n",
        "# Step 4: Prepare dataset again for modeling\n",
        "numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
        "X = numeric_data.drop(columns=['AAV'], errors='ignore')  # Features\n",
        "y = data['AAV']  # Target variable\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Train and evaluate Random Forest and Gradient Boosting again\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "print(\"\\nRandom Forest Updated Metrics:\")\n",
        "print(f\"R-squared: {r2_score(y_test, y_pred_rf):.2f}\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred_rf):.2f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred_rf):.2f}\")\n",
        "\n",
        "# Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "print(\"\\nGradient Boosting Updated Metrics:\")\n",
        "print(f\"R-squared: {r2_score(y_test, y_pred_gb):.2f}\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred_gb):.2f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred_gb):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T4wExDgIzf6"
      },
      "source": [
        "Still low. Let's work with some hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ_2-3kyKOJe"
      },
      "outputs": [],
      "source": [
        "# Random Forest Parameter Grid\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Gradient Boosting Parameter Grid\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Random Forest Randomized Search\n",
        "rf_random_search = RandomizedSearchCV(\n",
        "    estimator=RandomForestRegressor(random_state=42),\n",
        "    param_distributions=rf_param_grid,\n",
        "    n_iter=20,  # Number of random combinations to try\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "rf_random_search.fit(X_train, y_train)\n",
        "print(\"Best Random Forest Parameters:\", rf_random_search.best_params_)\n",
        "print(\"Best Random Forest Score (MSE):\", -rf_random_search.best_score_)\n",
        "\n",
        "# Gradient Boosting Randomized Search\n",
        "gb_random_search = RandomizedSearchCV(\n",
        "    estimator=GradientBoostingRegressor(random_state=42),\n",
        "    param_distributions=gb_param_grid,\n",
        "    n_iter=20,  # Number of random combinations to try\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "gb_random_search.fit(X_train, y_train)\n",
        "print(\"\\nBest Gradient Boosting Parameters:\", gb_random_search.best_params_)\n",
        "print(\"Best Gradient Boosting Score (MSE):\", -gb_random_search.best_score_)\n",
        "\n",
        "# Evaluate Random Forest\n",
        "y_pred_rf = rf_random_search.best_estimator_.predict(X_test)\n",
        "\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mse_rf)\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "mape_rf = mean_absolute_percentage_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "explained_variance_rf = explained_variance_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"\\nRandom Forest Final Metrics:\")\n",
        "print(f\"MSE: {mse_rf:.2f}\")\n",
        "print(f\"RMSE: {rmse_rf:.2f}\")\n",
        "print(f\"MAE: {mae_rf:.2f}\")\n",
        "print(f\"MAPE: {mape_rf:.2%}\")  # Show as percentage\n",
        "print(f\"R-squared: {r2_rf:.2f}\")\n",
        "print(f\"Explained Variance Score: {explained_variance_rf:.2f}\")\n",
        "\n",
        "# Evaluate Gradient Boosting\n",
        "y_pred_gb = gb_random_search.best_estimator_.predict(X_test)\n",
        "\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mse_gb)\n",
        "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
        "mape_gb = mean_absolute_percentage_error(y_test, y_pred_gb)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "explained_variance_gb = explained_variance_score(y_test, y_pred_gb)\n",
        "\n",
        "print(\"\\nGradient Boosting Final Metrics:\")\n",
        "print(f\"MSE: {mse_gb:.2f}\")\n",
        "print(f\"RMSE: {rmse_gb:.2f}\")\n",
        "print(f\"MAE: {mae_gb:.2f}\")\n",
        "print(f\"MAPE: {mape_gb:.2%}\")  # Show as percentage\n",
        "print(f\"R-squared: {r2_gb:.2f}\")\n",
        "print(f\"Explained Variance Score: {explained_variance_gb:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC_zh0MqSuVd"
      },
      "source": [
        "The results for both the Random Forest and Gradient Boosting models indicate relatively low predictive accuracy. With an \\( R^2 \\) score of 0.60 for both models, they explain approximately 60% of the variance in `AAV`. This suggests that while the models capture some meaningful patterns in the data, they leave a substantial portion of the variability unexplained. Additionally, the high Mean Absolute Percentage Error (MAPE) values of 143.91% (Random Forest) and 146.88% (Gradient Boosting) reflect significant prediction errors, especially for lower-salary players.\n",
        "\n",
        "Despite the low predictive accuracy, these models still serve as a useful baseline for defining `Overpaid`, `Fairly Paid`, and `Underpaid` categories. The predicted `AAV` values establish a systematic framework to benchmark actual salaries. By using an objective threshold (e.g., within 10% of predicted salary for `Fairly Paid`), the models enable a consistent methodology to classify player salary fairness, even if precise salary predictions are less reliable.\n",
        "\n",
        "The fairness classifications derived from these predictions will be instrumental in downstream tasks. This ensures that subsequent analyses, such as determining which player groups are most overpaid or underpaid, remain interpretable and actionable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfAFt1NWUTFl"
      },
      "source": [
        "**Interpretation**\n",
        "\n",
        "The **Proportion of Players by Salary Fairness** chart illustrates that the majority of players are either classified as \"Fairly Paid\" or \"Underpaid,\" with \"Overpaid\" players constituting the smallest group. This suggests that, based on the model, actual salaries are more aligned with predictions for a significant portion of the dataset.\n",
        "\n",
        "The **Distribution of Actual Salaries by Fairness Category** box plot highlights that \"Overpaid\" players generally have much higher actual salaries compared to the \"Fairly Paid\" and \"Underpaid\" groups. The spread of salaries is wide in the \"Overpaid\" category, indicating variability in overpayment, while \"Fairly Paid\" and \"Underpaid\" categories show much tighter distributions.\n",
        "\n",
        "The **Distribution of Predicted Salaries by Fairness Category** box plot shows that the model predicts significantly higher salaries for the \"Overpaid\" group compared to the \"Underpaid\" group, aligning with the fairness classification. The \"Fairly Paid\" group has predicted salaries closely concentrated around the middle range, which aligns with its definition. The patterns provide validation that the model's classifications of fairness are consistent with both actual and predicted salary trends.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Combine predictions and true salaries into a DataFrame for analysis\n",
        "classification_results = pd.DataFrame({\n",
        "    \"Actual_Salary\": y_test,  # Replace y_test with your actual salary values\n",
        "    \"Predicted_Salary\": y_pred_rf,  # Replace y_pred_rf with the best model's predictions\n",
        "})\n",
        "\n",
        "# Define salary categorization logic (example: thresholds for \"underpaid\" or \"overpaid\")\n",
        "def categorize_salary(row):\n",
        "    if row[\"Predicted_Salary\"] < 0.8 * row[\"Actual_Salary\"]:  # Less than 80% of actual salary\n",
        "        return \"Underpaid\"\n",
        "    elif row[\"Predicted_Salary\"] > 1.2 * row[\"Actual_Salary\"]:  # More than 120% of actual salary\n",
        "        return \"Overpaid\"\n",
        "    else:\n",
        "        return \"Fairly Paid\"\n",
        "\n",
        "classification_results[\"Category\"] = classification_results.apply(categorize_salary, axis=1)\n",
        "\n",
        "# Calculate proportions instead of counts\n",
        "category_proportions = classification_results[\"Category\"].value_counts(normalize=True)\n",
        "\n",
        "# Create a horizontal bar chart with proportions\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(category_proportions.index, category_proportions.values,\n",
        "                color=['lightgreen', 'lightcoral', 'gold'], edgecolor='black')\n",
        "\n",
        "# Add percentage labels to each bar\n",
        "for bar in bars:\n",
        "    plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height() / 2,\n",
        "             f\"{bar.get_width() * 100:.1f}%\", va='center', fontsize=12, fontweight='bold')\n",
        "\n",
        "# Customize chart appearance\n",
        "plt.title('Salary Categorization Breakdown Based on Predictions (Proportions)', fontsize=16, fontweight='bold', color='darkblue')\n",
        "plt.xlabel('Proportion of Players', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Salary Categories', fontsize=14, fontweight='bold')\n",
        "plt.xticks(ticks=[0, 0.2, 0.4, 0.6, 0.8, 1.0], labels=['0%', '20%', '40%', '60%', '80%', '100%'], fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Tight layout for better spacing\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3JyMKDETiGr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj2XckkQVF6n"
      },
      "source": [
        "## SVM to See which types of players are being paid fairly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3ETdQ4rZ0V6"
      },
      "source": [
        "I will use Optuna for hyperparameter tuning to optimize the performance of the SVM model efficiently. Optuna uses Bayesian optimization to intelligently explore the parameter space, reducing computation time compared to exhaustive methods like grid or random search."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugging: Check lengths\n",
        "print(\"Length of K-Means labels:\", len(kmeans.labels_))\n",
        "print(\"Number of rows in data:\", len(data))\n",
        "\n",
        "# Ensure the data used for K-Means matches the current DataFrame\n",
        "if len(kmeans.labels_) != len(data):\n",
        "    print(\"Mismatch detected! Ensure clustering data aligns with the current DataFrame.\")\n"
      ],
      "metadata": {
        "id": "FS3HnWXbqA9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Recreate the K-Means training data\n",
        "kmeans_features = top_features  # Use the features you passed to K-Means\n",
        "kmeans_training_data = data[kmeans_features].dropna()  # Exclude rows with missing values\n",
        "\n",
        "# Get the indices of the K-Means training data\n",
        "kmeans_data_index = kmeans_training_data.index\n",
        "\n",
        "# Compare the indices\n",
        "print(\"Indices of K-Means training data:\", kmeans_data_index)\n",
        "print(\"Indices of current data:\", data.index)\n",
        "\n",
        "# Find mismatched rows\n",
        "mismatched_rows = data.loc[~data.index.isin(kmeans_data_index)]\n",
        "print(\"Mismatched row(s):\", mismatched_rows)\n"
      ],
      "metadata": {
        "id": "vYrrsehXqJJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDcx8h1AVPsR"
      },
      "outputs": [],
      "source": [
        "# Step 1: Check for duplicate indices\n",
        "print(\"Duplicate indices in data:\", data.index.duplicated().sum())\n",
        "\n",
        "# Step 2: Drop duplicate indices if needed\n",
        "if data.index.duplicated().sum() > 0:\n",
        "    print(\"Dropping duplicate indices...\")\n",
        "    data = data[~data.index.duplicated(keep='first')].copy()\n",
        "\n",
        "# Step 3: Verify lengths after deduplication\n",
        "print(\"Length of K-Means labels (after deduplication):\", len(kmeans.labels_))\n",
        "print(\"Number of rows in data (after deduplication):\", len(data))\n",
        "\n",
        "# Step 4: Assign K-Means clusters\n",
        "if len(kmeans.labels_) == len(data):\n",
        "    data['Cluster'] = kmeans.labels_  # Assign clusters directly\n",
        "else:\n",
        "    raise ValueError(\"Length mismatch persists after handling duplicates.\")\n",
        "\n",
        "# Map cluster labels to descriptive names\n",
        "cluster_labels_map = {\n",
        "    0: \"Power Hitters\",\n",
        "    1: \"Balanced Hitters\",\n",
        "    2: \"Utility Players\"\n",
        "}\n",
        "data['Cluster_Label'] = data['Cluster'].map(cluster_labels_map)\n",
        "\n",
        "# Predict salaries if not already done\n",
        "if 'Predicted Salary' not in data.columns:\n",
        "    data['Predicted Salary'] = rf_model.predict(data[top_features + ['Cluster']])\n",
        "\n",
        "# Define threshold and classify fairness\n",
        "threshold = 0.1 * data['AAV'].mean()\n",
        "\n",
        "def classify_salary(actual, predicted, threshold):\n",
        "    if actual < predicted - threshold:\n",
        "        return \"Underpaid\"\n",
        "    elif actual > predicted + threshold:\n",
        "        return \"Overpaid\"\n",
        "    else:\n",
        "        return \"Fairly Paid\"\n",
        "\n",
        "data['Fairness'] = [\n",
        "    classify_salary(actual, predicted, threshold)\n",
        "    for actual, predicted in zip(data['AAV'], data['Predicted Salary'])\n",
        "]\n",
        "\n",
        "data['Fairness_Label'] = data['Fairness'].map({'Fairly Paid': 0, 'Underpaid': 1, 'Overpaid': 2})\n",
        "\n",
        "# Check and balance class distribution before splitting\n",
        "class_counts = data['Fairness_Label'].value_counts()\n",
        "print(\"Fairness label distribution before splitting:\\n\", class_counts)\n",
        "\n",
        "# Oversample minority classes if necessary\n",
        "if class_counts.min() < 2:\n",
        "    minority_classes = class_counts[class_counts < 2].index.tolist()\n",
        "    resampled_data = []\n",
        "    for label in class_counts.index:\n",
        "        subset = data[data['Fairness_Label'] == label]\n",
        "        if label in minority_classes:\n",
        "            subset = resample(\n",
        "                subset,\n",
        "                replace=True,\n",
        "                n_samples=2,  # Ensure at least 2 samples\n",
        "                random_state=42\n",
        "            )\n",
        "        resampled_data.append(subset)\n",
        "    data = pd.concat(resampled_data)\n",
        "\n",
        "# Prepare SVM Data\n",
        "X = data[top_features + ['Cluster']]\n",
        "y = data['Fairness_Label']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 3: Simplified Random Search with Reduced Trials\n",
        "reduced_svm_param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale']\n",
        "}\n",
        "\n",
        "svm_model = SVC(random_state=42)\n",
        "svm_random_search = RandomizedSearchCV(\n",
        "    estimator=svm_model,\n",
        "    param_distributions=reduced_svm_param_grid,\n",
        "    n_iter=5,\n",
        "    scoring='accuracy',\n",
        "    cv=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "svm_random_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate the SVM Model\n",
        "best_svm = svm_random_search.best_estimator_\n",
        "y_pred = best_svm.predict(X_test)\n",
        "\n",
        "print(\"Simplified Random Search Best Parameters:\", svm_random_search.best_params_)\n",
        "\n",
        "# Adjust labels dynamically based on classes in y_test\n",
        "present_classes = sorted(set(y_test))  # Get unique classes in y_test\n",
        "target_names = ['Fairly Paid', 'Underpaid', 'Overpaid']  # Full list of target names\n",
        "\n",
        "# Filter target_names to match the present classes\n",
        "filtered_target_names = [target_names[label] for label in present_classes]\n",
        "\n",
        "# Generate the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=filtered_target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=filtered_target_names,\n",
        "            yticklabels=filtered_target_names)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "# Step 6: Visualize Fairness by Cluster\n",
        "fairness_cluster_summary = data.groupby(['Cluster_Label', 'Fairness']).size().unstack(fill_value=0)\n",
        "fairness_cluster_summary.plot(kind='bar', stacked=True, figsize=(12, 6), colormap='viridis')\n",
        "plt.title(\"Fairness Categories by Clusters\")\n",
        "plt.xlabel(\"Player Cluster\")\n",
        "plt.ylabel(\"Number of Players\")\n",
        "plt.legend(title=\"Fairness Category\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYOryTbfVPEO"
      },
      "source": [
        "The classification report indicates that the SVM model is highly effective at identifying \"Underpaid\" players, with a precision of 0.92 and recall of 0.96, highlighting its strong performance in this category. However, the model struggles significantly with \"Overpaid\" players, achieving only 0.70 precision and 0.54 recall. This imbalance suggests that the model performs better at detecting players who are underpaid compared to those who are overpaid, likely due to the smaller representation of \"Overpaid\" players in the dataset.\n",
        "\n",
        "The confusion matrix further visualizes this performance, showing a dominant concentration of correct predictions for \"Underpaid\" players but significant misclassifications for \"Overpaid\" players, often being confused with the \"Underpaid\" category. This misclassification highlights the challenge in accurately identifying overpayment trends, which might require additional features or adjusted thresholds.\n",
        "\n",
        "The stacked bar chart provides further insight into fairness categorization across player clusters. \"Balanced Hitters\" and \"Utility Players\" are predominantly underpaid, suggesting systemic undervaluation in these groups. Conversely, \"Power Hitters\" show a more balanced distribution, with a significant proportion identified as overpaid. These findings emphasize the need for refined approaches to salary optimization that account for specific player types and their contributions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Can it be Improved through Boosting and Bagging"
      ],
      "metadata": {
        "id": "4FlMvgMCuDJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Ensure Clusters and Fairness Labels Exist\n",
        "data['Fairness_Label'] = data['Fairness'].map({'Fairly Paid': 0, 'Underpaid': 1, 'Overpaid': 2})\n",
        "X = data[top_features + ['Cluster']]  # Use top features and cluster as predictors\n",
        "y = data['Fairness_Label']\n",
        "\n",
        "# Step 2: Split the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 3: Random Forest with Random Search\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "rf_random_search = RandomizedSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_distributions=rf_param_grid,\n",
        "    n_iter=10,  # Fewer iterations for faster results\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "rf_random_search.fit(X_train, y_train)\n",
        "rf_best = rf_random_search.best_estimator_\n",
        "\n",
        "# Random Forest Evaluation\n",
        "rf_y_pred = rf_best.predict(X_test)\n",
        "present_classes_rf = unique_labels(y_test, rf_y_pred)  # Get classes present in y_test and rf_y_pred\n",
        "target_names_rf = [target for i, target in enumerate(['Fairly Paid', 'Underpaid', 'Overpaid']) if i in present_classes_rf]\n",
        "\n",
        "print(\"\\nRandom Forest Classification Report:\")\n",
        "print(classification_report(y_test, rf_y_pred, target_names=target_names_rf))\n",
        "\n",
        "# Confusion Matrix for Random Forest\n",
        "conf_matrix_rf = confusion_matrix(y_test, rf_y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_rf, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=target_names_rf,\n",
        "            yticklabels=target_names_rf)\n",
        "plt.title(\"Confusion Matrix - Random Forest\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Gradient Boosting with Random Search\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "gb_random_search = RandomizedSearchCV(\n",
        "    estimator=GradientBoostingClassifier(random_state=42),\n",
        "    param_distributions=gb_param_grid,\n",
        "    n_iter=10,  # Fewer iterations for faster results\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "gb_random_search.fit(X_train, y_train)\n",
        "gb_best = gb_random_search.best_estimator_\n",
        "\n",
        "# Gradient Boosting Evaluation\n",
        "gb_y_pred = gb_best.predict(X_test)\n",
        "present_classes_gb = unique_labels(y_test, gb_y_pred)  # Get classes present in y_test and gb_y_pred\n",
        "target_names_gb = [target for i, target in enumerate(['Fairly Paid', 'Underpaid', 'Overpaid']) if i in present_classes_gb]\n",
        "\n",
        "print(\"\\nGradient Boosting Classification Report:\")\n",
        "print(classification_report(y_test, gb_y_pred, target_names=target_names_gb))\n",
        "\n",
        "# Confusion Matrix for Gradient Boosting\n",
        "conf_matrix_gb = confusion_matrix(y_test, gb_y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_gb, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=target_names_gb,\n",
        "            yticklabels=target_names_gb)\n",
        "plt.title(\"Confusion Matrix - Gradient Boosting\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Fairness Distribution by Clusters\n",
        "fairness_cluster_summary = data.groupby(['Cluster', 'Fairness']).size().unstack(fill_value=0)\n",
        "fairness_cluster_summary.plot(kind='bar', stacked=True, figsize=(12, 6), colormap='viridis')\n",
        "plt.title(\"Fairness Categories by Clusters\")\n",
        "plt.xlabel(\"Player Cluster\")\n",
        "plt.ylabel(\"Number of Players\")\n",
        "plt.legend(title=\"Fairness Category\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r0EK6TP2uG-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results demonstrate a moderate level of success in identifying salary fairness categories using ensemble models like Random Forest and Gradient Boosting. The classification report for Gradient Boosting reveals strong performance for the \"Fairly Paid\" category with an F1-score of 0.74, but weaker performance for \"Underpaid\" (0.51) and \"Overpaid\" (0.15). This suggests the model is more adept at identifying fairly paid players, but struggles with the less represented \"Overpaid\" category, likely due to class imbalance.\n",
        "\n",
        "The confusion matrices further highlight these observations, as most misclassifications occur between \"Underpaid\" and \"Overpaid\" categories, indicating overlap in features or insufficient differentiation by the model. The fairness-by-cluster visualization reveals that \"Utility Players\" (Cluster 2) are predominantly underpaid, while \"Power Hitters\" (Cluster 0) are better distributed across fairness categories. This suggests that the model captures some meaningful patterns but still faces challenges with generalizing fairness across all clusters.\n",
        "\n",
        "Overall, while the models provide useful insights, the results indicate room for improvement in addressing class imbalance and refining feature selection or representation. Additional techniques, such as rebalancing classes or incorporating advanced ensemble methods, could improve predictive accuracy, especially for \"Underpaid\" and \"Overpaid\" categories.\n"
      ],
      "metadata": {
        "id": "Cp1gP8ajvVf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fairness Distribution by Cluster**"
      ],
      "metadata": {
        "id": "QeRM3CpSvz65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping for clusters to player categories\n",
        "cluster_labels_map = {\n",
        "    0: \"Power Hitters\",\n",
        "    1: \"Balanced Hitters\",\n",
        "    2: \"Utility Players\"\n",
        "}\n",
        "\n",
        "# Replace the cluster numbers in the table with their corresponding labels\n",
        "fairness_cluster_summary.index = fairness_cluster_summary.index.map(cluster_labels_map)\n",
        "\n",
        "# Display the updated table\n",
        "print(fairness_cluster_summary)\n"
      ],
      "metadata": {
        "id": "VadibTKRv31_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Power Hitters have a significant proportion of both \"Overpaid\" and \"Underpaid\" players, with relatively fewer categorized as \"Fairly Paid,\" highlighting a notable disparity in salary alignment within this group. Balanced Hitters show a more even distribution, but still have a notable number of \"Underpaid\" players. Utility Players, on the other hand, have the highest number of \"Fairly Paid\" players and very few \"Overpaid\" players, indicating that salaries for this group are generally more aligned with their performance."
      ],
      "metadata": {
        "id": "Ma-b2pyiwAm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Proportional Analysis**"
      ],
      "metadata": {
        "id": "50o7FwSMwBAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fairness_proportions = fairness_cluster_summary.div(fairness_cluster_summary.sum(axis=1), axis=0)\n",
        "print(fairness_proportions)\n"
      ],
      "metadata": {
        "id": "3YrPHJmuv_ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Power Hitters have a relatively balanced distribution, with 45.7% categorized as \"Underpaid,\" 30.5% as \"Overpaid,\" and 23.8% as \"Fairly Paid,\" indicating significant disparities in salary alignment. Balanced Hitters show a slightly better distribution, with 40.8% \"Underpaid,\" 23.2% \"Overpaid,\" and 36% \"Fairly Paid,\" reflecting a moderate alignment overall. Utility Players, however, stand out with 76.8% \"Fairly Paid,\" only 5.3% \"Overpaid,\" and 17.9% \"Underpaid,\" suggesting that this group experiences the highest salary alignment among the clusters."
      ],
      "metadata": {
        "id": "oVFyVthkw4-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization**"
      ],
      "metadata": {
        "id": "37xAQhT4w_uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fairness_cluster_summary.plot(kind='bar', stacked=True, figsize=(12, 6), colormap='viridis')\n",
        "plt.title(\"Fairness Categories by Clusters\")\n",
        "plt.xlabel(\"Player Cluster\")\n",
        "plt.ylabel(\"Number of Players\")\n",
        "plt.legend(title=\"Fairness Category\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dq_MPY1axBbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x='Cluster', y='AAV', hue='Fairness', data=data)\n",
        "plt.title(\"Actual Salary Distribution by Cluster and Fairness\")\n",
        "plt.show()\n",
        "\n",
        "sns.boxplot(x='Cluster', y='Predicted Salary', hue='Fairness', data=data)\n",
        "plt.title(\"Predicted Salary Distribution by Cluster and Fairness\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9Rl2uwALxH9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The salary distributions across clusters show significant variability, particularly in \"Power Hitters,\" where both actual and predicted salaries demonstrate a wide range, including several extreme outliers. Using neural network analysis, these outliers can be further evaluated and removed to improve fairness categorizations and refine salary predictions for greater alignment with cluster-specific performance metrics."
      ],
      "metadata": {
        "id": "TWcTs6aUxkhw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Networks for Further Analysis"
      ],
      "metadata": {
        "id": "kyNfWbAXxszY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "0zhp-HG8yBON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Normalize the feature set\n",
        "scaler = StandardScaler()\n",
        "numeric_features = ['barrel', 'home_run', 'HR', 'RBI', 'SLG', 'Predicted Salary', 'Cluster']  # Include relevant features\n",
        "X = data[numeric_features]\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 2: Encode the target variable (Fairness Labels)\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(data['Fairness_Label'])  # Ensure 'Fairness_Label' is numeric (0, 1, 2)\n",
        "y_categorical = to_categorical(y_encoded)  # Convert to one-hot encoding for multi-class classification\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "\n",
        "print(\"Data prepared:\")\n",
        "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Testing set: {X_test.shape}, {y_test.shape}\")"
      ],
      "metadata": {
        "id": "fGeWqQ5MxxnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Preparation"
      ],
      "metadata": {
        "id": "Q_Yg5UXTyVTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Correct column alignment for X_train and X_test\n",
        "X_train_df = pd.DataFrame(X_train, columns=data[top_features].columns[:X_train.shape[1]])\n",
        "X_test_df = pd.DataFrame(X_test, columns=data[top_features].columns[:X_test.shape[1]])\n",
        "\n",
        "# Ensure 'Cluster' is included in the datasets\n",
        "X_train_df['Cluster'] = data.loc[X_train_df.index, 'Cluster'].values\n",
        "X_test_df['Cluster'] = data.loc[X_test_df.index, 'Cluster'].values\n",
        "\n",
        "# Convert back to numpy arrays\n",
        "X_train_with_clusters = X_train_df.values\n",
        "X_test_with_clusters = X_test_df.values\n",
        "\n",
        "# Step 2: Build the Neural Network Model\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=X_train_with_clusters.shape[1], activation='relu'),  # Input layer with 64 neurons\n",
        "    Dropout(0.3),  # Dropout to prevent overfitting\n",
        "    Dense(32, activation='relu'),  # Hidden layer with 32 neurons\n",
        "    Dropout(0.3),\n",
        "    Dense(16, activation='relu'),  # Another hidden layer with 16 neurons\n",
        "    Dense(y_train.shape[1], activation='softmax')  # Output layer with softmax for multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',  # Adam optimizer\n",
        "              loss='categorical_crossentropy',  # Loss for multi-class classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Step 3: Train the Model\n",
        "history = model.fit(X_train_with_clusters, y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=50,  # Adjust epochs as needed\n",
        "                    batch_size=16,  # Mini-batch size\n",
        "                    verbose=1)\n",
        "\n",
        "# Step 4: Evaluate the Model\n",
        "loss, accuracy = model.evaluate(X_test_with_clusters, y_test)\n",
        "print(f\"\\nTest Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "# Step 5: Visualize Training Progress\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Step 6: Analyze Results by Cluster\n",
        "# Predict fairness categories for the test set\n",
        "y_pred = np.argmax(model.predict(X_test_with_clusters), axis=1)\n",
        "\n",
        "# Map predictions back to fairness categories\n",
        "fairness_pred = pd.Series(y_pred).map({0: 'Fairly Paid', 1: 'Underpaid', 2: 'Overpaid'})\n",
        "\n",
        "# Add predictions and clusters to a summary dataframe\n",
        "results_df = pd.DataFrame({\n",
        "    'Cluster': X_test_df['Cluster'],\n",
        "    'True Fairness': pd.Series(np.argmax(y_test, axis=1)).map({0: 'Fairly Paid', 1: 'Underpaid', 2: 'Overpaid'}),\n",
        "    'Predicted Fairness': fairness_pred\n",
        "})\n",
        "\n",
        "# Analyze fairness distribution by cluster\n",
        "fairness_by_cluster = results_df.groupby('Cluster')['Predicted Fairness'].value_counts(normalize=True).unstack()\n",
        "print(fairness_by_cluster)\n",
        "\n",
        "# Visualize fairness distribution by cluster\n",
        "fairness_by_cluster.plot(kind='bar', stacked=True, figsize=(12, 6), colormap='viridis')\n",
        "plt.title('Fairness Prediction Distribution by Cluster')\n",
        "plt.xlabel('Player Cluster')\n",
        "plt.ylabel('Proportion')\n",
        "plt.legend(title='Fairness Category')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NAJyujxiyX1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The neural network model demonstrates distinct insights into the salary fairness distribution across different player clusters. For \"Power Hitters\" (Cluster 0), the model predicts a relatively balanced distribution between \"Fairly Paid\" (39%) and \"Underpaid\" (35%), but also a noticeable share (26%) categorized as \"Overpaid,\" reflecting a mix of salary alignment within this group. In contrast, \"Balanced Hitters\" (Cluster 1) show the highest proportion of \"Fairly Paid\" players (54%), with lower proportions of \"Overpaid\" (18%) and \"Underpaid\" (27%), indicating better salary alignment overall. \"Utility Players\" (Cluster 2) feature the most evenly distributed fairness categories, with 39% \"Fairly Paid,\" 34% \"Overpaid,\" and 27% \"Underpaid,\" suggesting a diverse salary alignment within this group.\n",
        "\n",
        "The model's accuracy and loss curves indicate consistent improvements during training and validation phases, with a final accuracy around 70%. While the model provides valuable insights into the fairness of salary distributions within player clusters, the modest accuracy and overlapping proportions in some clusters suggest that further refinement, potentially with more features or advanced regularization, could improve classification performance and offer deeper insights into salary dynamics across player types.\n",
        "\n"
      ],
      "metadata": {
        "id": "DGzlMS3vy9Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/final_project.ipynb\" ./\n",
        "!jupyter nbconvert --to html \"final_project.ipynb\""
      ],
      "metadata": {
        "id": "mxFaR6yT1bdY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1x3JAuypn-LXC2zK5rVvOVnNGDlQgTTa_",
      "authorship_tag": "ABX9TyO8z92rqjvLYRUZouU4Teyj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}